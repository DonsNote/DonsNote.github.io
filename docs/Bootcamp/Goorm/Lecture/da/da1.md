---
layout: default
nav_order: 1
title: DA - 데이터 사고와 기초
description: "Data Analysis 1"
parent: DA
grand_parent: Goorm
has_children: false
---

# 제 1 강 - 데이터 사고와 기초

## 사전 질문
1. 어떤 기능이 사용자에게 도움이 되는 지에 대해, 직관적 판단, 데이터 중심 판단 이 둘을 어떤 식으로 활용해야 할까요?
    - 유저 플로우를 바탕으로 중심이 되는 기능이 무엇인지 파악한다.
    - 유저가 가장 많이 사용하는 기능에 대한 로그를 분석한다.
    - 이 두가지를 분석하여 고객 행동에 문제(뎁스, 판단, 실행 등)가 없는지 확인한다.
2. 데이터를 통해서 사용자의 행동을 분석할 때 알 수 있는것과 알 수 없는 것은 무엇일까요?
    - 고객이 사용하는 서비스의 기능중의 우선순위와 고객층을 데이터를 통해 알 수 있음
    - 사용중 고객이 느끼는 감정, 이해도(정말 이해해서 기능을 쓰고 있는지) 등을 알 수 없음.

## 데이터

### 프로덕트에서 데이터란 무엇인가?

데이터는 단순한 숫자가 아닌 **사용자 행동과 경험의 흔적**입니다. 프로덕트 관점에서 데이터는 고객이 남긴 디지털 발자국이며, 이를 통해 고객의 니즈와 문제점을 이해할 수 있습니다.

**데이터의 역할**:
- 📊 **의사결정의 근거**: 직관이 아닌 증거 기반 결정
- 🔍 **문제 발견**: 사용자가 어디서 이탈하는지 파악
- 📈 **성과 측정**: 목표 달성 여부 확인
- 🎯 **가설 검증**: 가정을 사실로 확인

---

#### 정량적 데이터

**정의**: 숫자로 측정 가능한 객관적 데이터

**특징**:
- 측정 가능하고 비교 가능
- 통계적 분석 가능
- 대규모 패턴 파악에 유리

**예시**:
```
- 일일 활성 사용자 수 (DAU): 10,000명
- 전환율: 3.5%
- 평균 세션 시간: 4분 30초
- 페이지 이탈률: 45%
- NPS 점수: 72점
```

**수집 방법**:
- 웹/앱 분석 도구 (Google Analytics, Mixpanel, Amplitude)
- A/B 테스트 결과
- 서버 로그 분석
- 설문조사 (리커트 척도)

---

#### 정성적 데이터

**정의**: 숫자로 측정하기 어려운 맥락과 감정을 담은 데이터

**특징**:
- 깊이 있는 인사이트 제공
- "왜?"에 대한 답을 제공
- 새로운 가설 발굴에 유리

**예시**:
```
- 사용자 인터뷰: "장바구니에 담았는데 결제가 너무 복잡해서 포기했어요"
- 고객 리뷰: "앱은 좋은데 알림이 너무 많아 불편해요"
- 사용성 테스트 관찰: 사용자가 메뉴를 찾느라 5초간 헤맴
- CS 문의 내용: "환불 절차가 어디 있는지 모르겠어요"
```

**수집 방법**:
- 1:1 사용자 인터뷰
- 사용성 테스트 (UT)
- 포커스 그룹 인터뷰 (FGI)
- 고객 지원 로그 분석
- 소셜 미디어 모니터링

---

#### 정량적 vs 정성적 데이터 비교

| 구분 | 정량적 데이터 | 정성적 데이터 |
|------|---------------|---------------|
| **질문** | "얼마나?" "몇 명?" | "왜?" "어떻게?" |
| **형태** | 숫자, 통계 | 텍스트, 관찰 |
| **분석** | 통계적 분석 | 테마 분석, 해석 |
| **장점** | 객관성, 비교 가능 | 깊이, 맥락 이해 |
| **단점** | "왜?"를 설명 못함 | 주관적, 일반화 어려움 |
| **활용** | 문제 규모 파악 | 문제 원인 파악 |

**최적의 접근**:
```
정량적 데이터: "전환율이 30% 하락했다" (What)
         ↓
정성적 데이터: "새 UI가 혼란스러워서 포기했다" (Why)
         ↓
해결책 도출: UX 개선 → 재측정
```

---

### 질문 중심 접근법

좋은 데이터 분석은 **좋은 질문**에서 시작됩니다. 질문의 품질이 데이터 분석의 가치를 결정합니다.

#### 약한 질문

**특징**:
- 목적이 불명확
- 실행 가능한 인사이트 도출 어려움
- 모호하고 광범위함

**예시**:
```
❌ "우리 서비스는 잘 되고 있나요?"
   → 기준이 없음. "잘"의 정의가 모호

❌ "사용자들이 좋아하는 것 같나요?"
   → 측정 불가능. 감정적 표현

❌ "데이터 좀 분석해주세요"
   → 목적 불명확. 무엇을 알고 싶은지 모름

❌ "매출이 왜 떨어졌나요?"
   → 너무 광범위. 분석 방향 설정 어려움
```

**문제점**:
- 분석 방향 설정 불가
- 시간과 리소스 낭비
- 실행으로 이어지지 않음

---

#### 강한 질문

**특징**:
- 구체적이고 측정 가능
- 가설 기반
- 실행 가능한 결과물 예상

**예시**:
```
✅ "지난 달 대비 결제 완료율이 왜 15% 하락했는가?"
   → 구체적인 지표와 기간 명시

✅ "신규 가입 후 7일 이내 재방문율이 30% 미만인 이유는?"
   → 측정 가능하고 명확한 기준

✅ "장바구니 이탈의 주요 원인 Top 3는 무엇인가?"
   → 우선순위화 가능

✅ "프리미엄 요금제로 전환하는 사용자의 특징은?"
   → 실행 가능한 세그먼트 발굴
```

**강한 질문 만들기 SMART 기법**:
```
S (Specific): 구체적인 대상과 범위
M (Measurable): 측정 가능한 지표
A (Actionable): 실행 가능한 결과물
R (Relevant): 비즈니스 목표와 연관
T (Time-bound): 기간 명시
```

**변환 예시**:
```
약한 질문: "사용자들이 앱을 잘 쓰고 있나요?"
         ↓
강한 질문: "지난 30일 기준, 주 3회 이상 앱을 사용하는
         Power User 비율이 목표 25%에 도달했는가?"
```

---

### 데이터의 사각지대 인식하기

데이터만으로는 **모든 것을 알 수 없습니다**. 좋은 PM은 데이터의 한계를 인식하고 이를 보완합니다.

#### 1. 부재 데이터 (Missing Data)

**정의**: 수집되지 않거나 수집할 수 없는 데이터

**예시**:
```
- 앱을 설치했다가 바로 삭제한 사용자
- 회원가입 없이 이탈한 방문자
- 오프라인에서 발생한 행동
- 경쟁사로 이탈한 고객의 이유
```

**보완 방법**:
- 익명 사용자 트래킹
- 이탈 설문 (Exit Survey)
- 경쟁사 리뷰 분석
- 비사용자 인터뷰

---

#### 2. 맥락 데이터 (Contextual Data)

**정의**: 행동의 배경과 상황에 대한 정보

**예시**:
```
데이터: 사용자가 오후 11시에 앱 사용 시간이 증가
맥락 부재: 왜 그 시간에 사용하는지 알 수 없음
실제 맥락:
  - 퇴근 후 여유 시간?
  - 불면증으로 깨어 있음?
  - 해외 출장 중 시차?
```

**보완 방법**:
- 사용자 인터뷰로 맥락 파악
- 추가 데이터 포인트 수집 (위치, 디바이스)
- 사용자 저니 맵핑

---

#### 3. 감정 데이터 (Emotional Data)

**정의**: 사용자의 감정 상태와 만족도

**예시**:
```
데이터: 사용자가 10분간 페이지에 머무름
가능한 해석:
  ✅ 콘텐츠에 몰입 → 만족
  ❌ 정보를 찾지 못해 헤맴 → 불만

데이터만으로는 구분 불가
```

**보완 방법**:
- 마이크로 설문 (이모지 피드백)
- 세션 리플레이 분석
- 감정 분석 (Sentiment Analysis)
- 직접 인터뷰

---

### 데이터 해석의 함정

데이터를 잘못 해석하면 **잘못된 의사결정**으로 이어집니다. PM은 다음 함정들을 경계해야 합니다.

#### 1. 상관관계와 인과관계 혼동

**정의**: 두 변수가 함께 변한다고 해서 원인-결과 관계가 있는 것은 아님

**예시**:
```
상관관계: 아이스크림 판매량 ↑ = 익사 사고 ↑
인과관계?: 아이스크림이 익사를 유발? ❌
실제 원인: 여름(더운 날씨)이라는 공통 원인

프로덕트 예시:
상관관계: 앱 사용 시간 ↑ = 결제 ↑
잘못된 해석: 사용 시간을 늘리면 결제가 늘어날 것
실제: 결제 의향이 높은 사람이 사용 시간도 긴 것
```

**검증 방법**:
- A/B 테스트로 인과관계 확인
- 제3의 변수 통제
- 시간적 선후관계 확인

---

#### 2. 확증 편향 (Confirmation Bias)

**정의**: 자신의 가설을 확인하는 데이터만 선택적으로 해석

**예시**:
```
가설: "새 디자인이 더 좋다"
데이터:
  - 체류 시간 5% 증가 ✅ (채택)
  - 전환율 10% 감소 ❌ (무시)
  - 이탈률 8% 증가 ❌ (무시)

결론: "새 디자인이 효과적이다" → 잘못된 결론
```

**방지 방법**:
- 반증 데이터 적극 탐색
- Devil's Advocate 지정
- 사전에 성공/실패 기준 정의
- 제3자 리뷰

---

#### 3. 생존 편향 (Survivorship Bias)

**정의**: 살아남은 사례만 분석하고 실패 사례를 무시

**예시**:
```
잘못된 분석:
  "성공한 스타트업은 모두 피벗을 했다"
  → 피벗하면 성공한다?

간과된 사실:
  피벗 후 실패한 더 많은 스타트업은 분석에서 제외됨

프로덕트 예시:
  "충성 고객 인터뷰 결과, 모두 기능 A를 좋아함"
  → 기능 A 때문에 떠난 고객은 인터뷰 대상이 아님
```

**방지 방법**:
- 이탈 고객 분석 병행
- 전체 모집단 고려
- 실패 사례 별도 분석

---

#### 4. 평균의 오류 (Average Trap)

**정의**: 평균값이 실제 분포를 왜곡

**예시**:
```
평균 세션 시간: 5분

실제 분포:
  - 50% 사용자: 1분 미만 (바로 이탈)
  - 30% 사용자: 3분
  - 20% 사용자: 15분 (Power User)

평균 5분은 어떤 그룹도 대표하지 못함
```

**방지 방법**:
- 중앙값, 분위수 함께 확인
- 분포 그래프 시각화
- 세그먼트별 분석

---

#### 5. 과도한 패턴화 (Over-patterning)

**정의**: 우연한 변동을 의미 있는 패턴으로 해석

**예시**:
```
데이터: 지난 3일간 가입자 수 5% 증가
잘못된 해석: "성장 추세다! 마케팅 효과!"
실제: 자연적인 변동 범위 내 (통계적 유의미하지 않음)
```

**방지 방법**:
- 통계적 유의성 검정
- 충분한 샘플 크기 확보
- 장기 추세와 비교
- 노이즈 vs 시그널 구분

---

#### 6. 측정 왜곡 (Measurement Distortion)

**정의**: 측정 방법 자체가 결과에 영향을 미침

**예시**:
```
측정: "이 기능이 유용합니까?" 설문
왜곡:
  - 사회적 바람직성 편향 (좋다고 답하는 경향)
  - 설문 문구가 긍정적 응답 유도

측정: 고객 만족도 조사 (구매 직후)
왜곡: 구매 직후는 긍정 감정 상태 → 실제보다 높은 점수
```

**방지 방법**:
- 중립적 문항 설계
- 행동 데이터와 교차 검증
- 다양한 시점에서 측정
- 블라인드 테스트

---

### 데이터 기반 접근의 단계

데이터 분석은 **4단계**로 발전하며, 각 단계마다 질문과 가치가 달라집니다.

```
복잡도 & 가치
    ↑
    │           ④ 처방적 분석
    │          /  "무엇을 해야 하는가?"
    │         /
    │        ③ 예측적 분석
    │       /  "무엇이 일어날 것인가?"
    │      /
    │     ② 진단적 분석
    │    /  "왜 일어났는가?"
    │   /
    │  ① 기술적 분석
    │ /  "무엇이 일어났는가?"
    └─────────────────────────→ 시간
```

---

#### 기술적 분석 (Descriptive Analytics)

**질문**: "무엇이 일어났는가?" (What happened?)

**목적**: 과거와 현재 상태를 객관적으로 파악

**예시**:
```
- 지난 달 DAU: 50,000명
- 이번 주 전환율: 3.2%
- 오늘 신규 가입자: 500명
- 평균 세션 시간: 4분 30초
```

**도구**:
- 대시보드 (Google Analytics, Tableau)
- 리포트 자동화
- KPI 모니터링

**PM의 활용**:
- 현황 파악 및 보고
- 이상 징후 감지
- 벤치마크 설정

---

#### 진단적 분석 (Diagnostic Analytics)

**질문**: "왜 일어났는가?" (Why did it happen?)

**목적**: 현상의 원인을 파악

**예시**:
```
현상: 결제 완료율 20% 하락
진단:
  - 결제 페이지 로딩 속도 3초 → 7초로 증가
  - 특정 결제 수단 오류율 상승
  - 새 UI에서 결제 버튼 위치 변경
```

**방법**:
- 드릴다운 분석
- 상관관계 분석
- 세그먼트 비교
- 퍼널 분석

**PM의 활용**:
- 문제 원인 규명
- 개선 포인트 발굴
- 가설 수립

---

#### 예측적 분석 (Predictive Analytics)

**질문**: "무엇이 일어날 것인가?" (What will happen?)

**목적**: 미래 트렌드와 행동 예측

**예시**:
```
- 이탈 예측: "이 사용자는 30일 내 이탈할 확률 85%"
- 수요 예측: "다음 달 예상 주문량 10,000건"
- LTV 예측: "이 고객의 예상 평생 가치 ₩150,000"
- 전환 예측: "이 사용자가 구매할 확률 40%"
```

**방법**:
- 머신러닝 모델
- 회귀 분석
- 시계열 분석
- 코호트 분석

**PM의 활용**:
- 선제적 대응 (이탈 방지 캠페인)
- 리소스 계획
- 투자 의사결정

---

#### 처방적 분석 (Prescriptive Analytics)

**질문**: "무엇을 해야 하는가?" (What should we do?)

**목적**: 최적의 행동 방안 제시

**예시**:
```
분석 결과:
  "이탈 위험 고객에게 20% 할인 쿠폰 발송 시,
   이탈률 35% 감소, 예상 수익 증가 ₩50M"

추천 행동:
  - 대상: 이탈 위험 점수 상위 20% 고객
  - 시점: 마지막 활동 후 7일차
  - 메시지: 개인화된 할인 제안
  - 채널: 푸시 알림 + 이메일
```

**방법**:
- 최적화 알고리즘
- 시뮬레이션
- 의사결정 트리
- A/B 테스트 자동화

**PM의 활용**:
- 자동화된 의사결정
- 개인화 추천
- 실시간 최적화

---

### 데이터 기반 PM의 5가지 습관

#### 1. 끊임없이 질문하기

**핵심**: 현상 뒤에 숨은 "왜?"를 지속적으로 탐구

**실천 방법**:
```
5 Whys 기법 활용:
1. 왜 전환율이 떨어졌나? → 결제 페이지 이탈 증가
2. 왜 결제 페이지에서 이탈하나? → 로딩이 느림
3. 왜 로딩이 느려졌나? → 새 이미지 추가로 용량 증가
4. 왜 이미지 최적화를 안 했나? → 프로세스 누락
5. 왜 프로세스가 누락됐나? → 체크리스트 부재
```

**습관화**:
- 매일 1개 지표에 대해 "왜?" 질문
- 데이터 리뷰 미팅에서 질문 목록 준비
- 가정을 명시적으로 기록

---

#### 2. 작은 실험으로 빠르게 학습하기

**핵심**: 큰 결정 전에 작은 실험으로 검증

**실천 방법**:
```
가설: "온보딩 튜토리얼 추가 시 리텐션 10% 상승"

작은 실험:
- 대상: 신규 가입자 1,000명 (전체의 5%)
- 기간: 2주
- 측정: 7일 리텐션

결과에 따라:
- 성공 → 전체 롤아웃
- 실패 → 빠른 피벗
```

**습관화**:
- 모든 기능에 A/B 테스트 고려
- 실험 백로그 관리
- 실패한 실험도 문서화

---

#### 3. 데이터와 사용자 공감 연결하기

**핵심**: 숫자 뒤에 있는 사람을 잊지 않기

**실천 방법**:
```
데이터: 이탈률 45%
숫자 해석: "거의 절반이 떠난다"
공감 연결: "100명 중 45명이 우리 서비스에서
           원하는 것을 찾지 못하고 실망해서 떠났다.
           그들은 어떤 기대를 갖고 왔을까?"
```

**습관화**:
- 월 1회 이상 사용자 직접 인터뷰
- 고객 지원 로그 정기 리뷰
- 세션 리플레이 시청 (주 30분)
- 데이터 리뷰 시 사용자 스토리 공유

---

#### 4. 가설을 명시적으로 문서화하기

**핵심**: 암묵적 가정을 명확하게 기록

**문서화 템플릿**:
```
가설: [무엇이] [어떻게 되면] [결과가] 나타날 것이다

예시:
가설: 결제 버튼 색상을 빨간색으로 변경하면,
      클릭률이 10% 상승할 것이다.

배경: 현재 파란색 버튼이 배경과 대비가 약함
측정: 결제 버튼 CTR
성공 기준: 10% 이상 상승
실험 기간: 2주
예상 위험: 브랜드 일관성 저하
```

**습관화**:
- 모든 실험 전 가설 문서 작성
- 결과와 함께 가설 리뷰
- 실패한 가설도 아카이빙

---

#### 5. 결과를 겸손하게 해석하기

**핵심**: 데이터의 한계를 인정하고 과신하지 않기

**겸손한 해석**:
```
❌ 과신:
"데이터가 이렇게 말하니까 확실히 맞습니다"

✅ 겸손:
"현재 데이터에 따르면 이런 경향이 보입니다.
다만, 샘플 크기가 작고 계절적 요인을
고려하지 못한 한계가 있습니다."
```

**실천 방법**:
- 항상 한계와 가정 명시
- 신뢰 구간 함께 보고
- 대안 가설 고려
- "모른다"고 말할 용기

**습관화**:
- 분석 보고 시 "한계" 섹션 필수 포함
- 정기적으로 과거 결론 재검토
- 반증 데이터 적극 탐색


## 과제

### 연구 과제
1. 자신이 오랫동안 사용한 앱을 하나 고릅니다. 그 앱의 PM이 볼 수 있는 데이터(접속 시간, 클릭한 버튼, 체류 시간 등)를 5개 이상 나열해 보십시오. 그 데이터들만으로 "당신이 왜 그 앱을 계속 쓰는지" 설명이 되나요?
2. 위 앱에서(아니면 새로운 앱에서) 메뉴나 카테고리의 구분을 하나 선택해 살펴봅니다. 이 카테고리 구성이 직관적이지 않다면, 나의 직관으로 재구성해보고, 이를 검증하기 위해 어떤 데이터를 분석해야하는지 생각해 봅니다.
3. 자주 방문하는 쇼핑몰을 하나 선택해 "결제 페이지에서 60%가 이탈한다"는 데이터가 있다고 가정해봅니다. 이 수치를 개선하기 위해 어떤 제안을 할 수 있을까요? 이 제안이 타당하려면 추가로 어떤 정보가 필요한가요?


### 실전 과제
1. 앱을 하나 설정해, 그 중 설정한 핵심 가설을 하나 선택해 이 문제에 대해 정성적, 정량적으로 충분히 검증되지 않은 부분에 대해 검토합니다.
2. 이 가설을 뒷받침하기 위해 필요한 데이터 분석은 무엇인지에 대해 생각해 봅니다. 어떤 데이터가 필요하고 어떤 분석 접근이 필요한지에 대해 생각해 봅니다.
3. 이를 바탕으로 이 가설을 검증하기 위한 구체적인 행동을 제안해 봅니다. 분석, 가설, 행동을 연결시켜 최종적으로 데이터 스토리텔링을 구성해 봅니다.


## 참고 자료
- [1강 연구 과제 PDF](/assets/pdf/goormda1iw.pdf)
- [1강 실전 과제 PDF](/assets/pdf/goormda1gw.pdf)

### 학습 자료 및 출처

#### 서적

- **"Lean Analytics"** - Alistair Croll, Benjamin Yoskovitz
  데이터 기반 의사결정과 스타트업 지표 분석의 기본서

- **"Measure What Matters"** - John Doerr
  OKR과 핵심 지표 설정에 대한 프레임워크

- **"Thinking, Fast and Slow"** - Daniel Kahneman
  인지 편향과 의사결정에 대한 심리학적 기반

- **"How to Measure Anything"** - Douglas W. Hubbard
  측정 불가능해 보이는 것들을 측정하는 방법론

- **"Storytelling with Data"** - Cole Nussbaumer Knaflic
  데이터 시각화와 스토리텔링

#### 관련 강의 및 코스

- [Google Data Analytics Professional Certificate](https://www.coursera.org/professional-certificates/google-data-analytics) - 데이터 분석 기초부터 실무까지 체계적 학습
- [Product Analytics Micro-Certification (Pendo)](https://www.pendo.io/product-analytics-certification/) - 제품 분석 전문 인증 과정
- [Reforge - Product Analytics](https://www.reforge.com/) - PM을 위한 고급 제품 분석 과정
- [DataCamp - Data Analyst Track](https://www.datacamp.com/tracks/data-analyst-with-python) - Python 기반 데이터 분석 실습

#### 실무 사례 참고

- [Amplitude Blog](https://amplitude.com/blog) - 제품 분석 사례 및 베스트 프랙티스
- [Mixpanel Resources](https://mixpanel.com/blog/) - 이벤트 기반 분석 및 사용자 행동 분석 사례
- [Mode Analytics Blog](https://mode.com/blog/) - SQL 기반 분석 및 데이터 시각화 사례
- [Towards Data Science (Medium)](https://towardsdatascience.com/) - 데이터 사이언스 실무 사례 및 튜토리얼
- [First Round Review - Data Articles](https://review.firstround.com/) - 스타트업 데이터 활용 사례

#### YouTube

- [StatQuest with Josh Starmer](https://www.youtube.com/@statquest) - 통계와 머신러닝 개념을 쉽게 설명
- [Alex The Analyst](https://www.youtube.com/@AlexTheAnalyst) - 데이터 분석 실무 튜토리얼
- [Lenny's Podcast](https://www.youtube.com/@LennysPodcast) - PM의 데이터 활용 사례 및 인터뷰
- [Data School](https://www.youtube.com/@dataschool) - 데이터 분석 도구 활용법

#### 커뮤니티

- [dbt Community](https://www.getdbt.com/community/) - 데이터 엔지니어링 및 분석 커뮤니티
- [Data Science subreddit](https://www.reddit.com/r/datascience/) - 데이터 사이언스 토론 및 질의응답
- [Analytics subreddit](https://www.reddit.com/r/analytics/) - 분석 도구 및 방법론 토론
- [Locally Optimistic](https://locallyoptimistic.com/) - 데이터 리더십 커뮤니티 블로그
- [DataTalks.Club](https://datatalks.club/) - 데이터 엔지니어링 및 분석 학습 커뮤니티

#### 도구 및 프로토 타이핑

- [Google Analytics](https://analytics.google.com/) - 웹/앱 트래픽 분석 기본 도구
- [Amplitude](https://amplitude.com/) - 제품 분석 및 사용자 행동 분석
- [Mixpanel](https://mixpanel.com/) - 이벤트 기반 사용자 분석
- [Hotjar](https://www.hotjar.com/) - 세션 리플레이 및 히트맵
- [FullStory](https://www.fullstory.com/) - 사용자 경험 분석
- [Tableau](https://www.tableau.com/) - 데이터 시각화 및 대시보드
- [Looker](https://looker.com/) - BI 및 데이터 탐색
- [Mode Analytics](https://mode.com/) - SQL 기반 데이터 분석 환경
- [Google BigQuery](https://cloud.google.com/bigquery) - 클라우드 데이터 웨어하우스
- [Pandas](https://pandas.pydata.org/) - Python 데이터 분석 라이브러리
- [Notion](https://www.notion.so/) - 가설 문서화 및 실험 기록
- [Coda](https://coda.io/) - 협업 문서 및 데이터 관리